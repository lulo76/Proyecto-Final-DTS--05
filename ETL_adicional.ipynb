{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables para la conexión\n",
    "############################\n",
    "HOST = 'localhost'\n",
    "PORT = 3306\n",
    "USER = 'root'\n",
    "PASSWORD = '123456789'\n",
    "DATABASE = 'olist'\n",
    "############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOST = 'database-1.cjevabxalgu3.us-east-1.rds.amazonaws.com'\n",
    "#PORT = 3306\n",
    "#USER = 'admin'\n",
    "#PASSWORD = 'henry1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db():\n",
    "    #crear conexion\n",
    "    con = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        user=USER,\n",
    "        password=PASSWORD\n",
    "    )\n",
    "    cur = con.cursor()\n",
    "    #crear la base de datos\n",
    "    cur.execute(\"DROP DATABASE IF EXISTS \"+DATABASE)\n",
    "    cur.execute(\"CREATE DATABASE \"+DATABASE)\n",
    "    con.close()\n",
    "\n",
    "def extract():\n",
    "    #cargar los datasets\n",
    "    df_customers= pd.read_csv('https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/Datasets/olist_customers_dataset.csv')\n",
    "    df_geolocation= pd.read_csv('https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/Datasets/olist_geolocation_dataset.csv')\n",
    "    df_order_items= pd.read_csv('https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/Datasets/olist_order_items_dataset.csv')\n",
    "    df_reviews = pd.read_csv('https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/Datasets/olist_order_reviews_dataset.csv')\n",
    "    df_orders = pd.read_csv('https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/Datasets/olist_orders_dataset.csv')\n",
    "    df_sellers=pd.read_csv('https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/Datasets/olist_sellers_dataset.csv')\n",
    "    df_products=pd.read_csv(\"https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/Datasets/olist_products_dataset.csv\")\n",
    "    data = {\n",
    "        'df_customers': df_customers, \n",
    "        'df_geolocation': df_geolocation, \n",
    "        'df_order_items': df_order_items,\n",
    "        'df_reviews': df_reviews,\n",
    "        'df_orders': df_orders,\n",
    "        'df_sellers': df_sellers,\n",
    "        'df_products': df_products\n",
    "        }\n",
    "\n",
    "    return data\n",
    "\n",
    "def transform(data):\n",
    "                 \n",
    "    \"\"\" \n",
    "    Esta función realiza todas las tareas de ETL necesarias para un grupo de datos.\n",
    "    Parametro: data (diccionario)\n",
    "\n",
    "    Retorna: un diccionario con todas las transformaciones realizadas\n",
    "    \"\"\"         \n",
    "    \n",
    "    df_customers= data['df_customers']\n",
    "    df_geolocation=data['df_geolocation']\n",
    "    df_order_items= data['df_order_items']\n",
    "    df_reviews= data['df_reviews']\n",
    "    df_orders= data['df_orders']\n",
    "    df_sellers= data['df_sellers']\n",
    "    df_products= data['df_products']\n",
    "    #Transformaciones para cada DF\n",
    "    \n",
    "    #Customers\n",
    "    # Renombramos la columna de codigo postal.\n",
    "    df_customers.rename(columns = {'customer_zip_code_prefix':'cus_zip_code'}, inplace=True)\n",
    "    #modifico el nombre de las ciudades con la primer letra mayuscula\n",
    "    #df_customers = df_customers['customer_city'].str.capitalize()\n",
    "    df_customers['customer_city'] = df_customers['customer_city'].str.capitalize()\n",
    "\n",
    "    #Geolocation\n",
    "    #Dropear duplicados de zip code\n",
    "    df_geolocation.drop_duplicates(['geolocation_zip_code_prefix'], inplace=True)\n",
    "    # Renombramos las columnas.\n",
    "    df_geolocation.rename(columns = {'geolocation_zip_code_prefix':'geo_zip_code'}, inplace=True)\n",
    "    df_geolocation.rename(columns = {'geolocation_lat':'geo_lat'}, inplace=True)\n",
    "    df_geolocation.rename(columns = {'geolocation_lng':'geo_lng'}, inplace=True)\n",
    "    df_geolocation.rename(columns = {'geolocation_city':'geo_city'}, inplace=True)\n",
    "    df_geolocation.rename(columns = {'geolocation_state':'geo_state'}, inplace=True)\n",
    "    \n",
    "    #Order Items\n",
    "    #quitar espacio izquierdo\n",
    "    df_order_items['shipping_limit_date']= df_order_items['shipping_limit_date'].str.lstrip()\n",
    "    #quitar espacio derecho\n",
    "    df_order_items['shipping_limit_date']= df_order_items['shipping_limit_date'].str.rstrip()\n",
    "    #reemplazar el espacio vacio por coma\n",
    "    df_order_items['shipping_limit_date']=df_order_items['shipping_limit_date'].str.replace(' ', ',')\n",
    "    #separar la listta en columna por , \n",
    "    df_order_items['shipping_limit_date']= df_order_items['shipping_limit_date'].str.split(',')\n",
    "    #asignar nuevos valores6\n",
    "    df_order_items[['fecha_limite', 'hora_limite']] = pd.DataFrame(df_order_items.shipping_limit_date.values.tolist(), \n",
    "                                                            columns=['fecha_limite', 'hora_limite'])\n",
    "    #dropear shipping date\n",
    "    df_order_items.drop(['shipping_limit_date'], axis=1, inplace=True)\n",
    "    #cambiar formato a datetime\n",
    "    df_order_items['fecha_limite']= pd.to_datetime(df_order_items['fecha_limite'])\n",
    "    #cambiar formato a datetime\n",
    "    df_order_items['hora_limite']= pd.to_datetime(df_order_items['hora_limite'])\n",
    "\n",
    "    #Reviews\n",
    "    # Eliminar id's duplicados\n",
    "    df_reviews.drop_duplicates(['review_id'], inplace=True)\n",
    "    # Eliminar columna de titulos de comentarios\n",
    "    df_reviews.drop(['review_comment_title'], axis=1, inplace=True)\n",
    "    # Borrar espacio vacio izquierdo y derecho.\n",
    "    df_reviews['review_comment_message'] = df_reviews['review_comment_message'].str.lstrip() \n",
    "    df_reviews['review_comment_message'] = df_reviews['review_comment_message'].str.rstrip()\n",
    "    # Rellenarmos NaN con \"sin datos\"\n",
    "    df_reviews['review_comment_message'].fillna('Sin Dato', inplace = True)\n",
    "       \n",
    "\n",
    "    #Orders\n",
    "    # Crear las columnas con diferencia de dias\n",
    "    df_orders ['dif_buy_cust'] = (pd.to_datetime(df_orders['order_delivered_customer_date']) - pd.to_datetime(df_orders['order_purchase_timestamp'])).dt.days\n",
    "    df_orders ['dif_buy_est'] = (pd.to_datetime(df_orders['order_estimated_delivery_date']) - pd.to_datetime(df_orders['order_purchase_timestamp'])).dt.days\n",
    "    df_orders ['dif_cust_est'] = (pd.to_datetime(df_orders['order_estimated_delivery_date']) - pd.to_datetime(df_orders['order_delivered_customer_date'])).dt.days\n",
    "    # Llenar los NaN vacios\n",
    "    df_orders['order_approved_at'].fillna('Sin Dato', inplace = True)\n",
    "    df_orders['order_delivered_carrier_date'].fillna('Sin Dato', inplace = True)\n",
    "    df_orders['order_delivered_customer_date'].fillna('Sin Dato', inplace = True)\n",
    "    df_orders['dif_buy_cust'].fillna('Sin Dato', inplace = True)\n",
    "    df_orders['dif_cust_est'].fillna('Sin Dato', inplace = True)\n",
    "    # Eliminamos la columna order_status\n",
    "    df_orders.drop(['order_status'], axis = 1, inplace=True)\n",
    "    \n",
    "\n",
    "    #Sellers\n",
    "    # Renombramos las columnas.\n",
    "    df_sellers.rename(columns = {'seller_zip_code_prefix':'sel_zip_code'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #Products\n",
    "    # dropeamos columnas que no vamos a utilizar\n",
    "    df_products.drop(['product_name_lenght'],axis=1, inplace=True)\n",
    "    df_products.drop(['product_description_lenght'], axis=1, inplace=True)\n",
    "    #dropeamos datas vacios\n",
    "    df_products.dropna(inplace=True)\n",
    "    data = {\n",
    "        'df_customers': df_customers, \n",
    "        'df_geolocation': df_geolocation, \n",
    "        'df_order_items': df_order_items,\n",
    "        'df_reviews': df_reviews,\n",
    "        'df_orders': df_orders,\n",
    "        'df_sellers': df_sellers,\n",
    "        'df_products': df_products\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load(data):\n",
    "    #crear la conexion\n",
    "    con = create_engine('mysql+mysqlconnector://'+USER+':'+PASSWORD+'@'+HOST+':'+str(PORT)+'/'+DATABASE)\n",
    "    #cargar los datasets en las tablas sql\n",
    "    for table in data:\n",
    "        df = data[table]\n",
    "        df.to_sql(table[3:], con=con, index=False)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data():\n",
    "    #crear la conexion\n",
    "    con = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        passwd=PASSWORD,\n",
    "        db=DATABASE\n",
    "    )\n",
    "    #modificar tipos de datos para garantizar compatibilidad\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"ALTER TABLE customers MODIFY customer_id VARCHAR(50);\")\n",
    "    cur.execute(\"ALTER TABLE customers MODIFY cus_zip_code INT;\")\n",
    "    cur.execute(\"ALTER TABLE geolocation MODIFY geo_zip_code INT;\")\n",
    "    cur.execute(\"ALTER TABLE order_items MODIFY order_id VARCHAR (50);\")\n",
    "    cur.execute(\"ALTER TABLE order_items MODIFY product_id VARCHAR (50);\")\n",
    "    cur.execute(\"ALTER TABLE order_items MODIFY seller_id VARCHAR (50);\")\n",
    "    cur.execute(\"ALTER TABLE order_items MODIFY order_item_id INT;\")\n",
    "    cur.execute(\"ALTER TABLE orders MODIFY order_id VARCHAR(50);\")\n",
    "    cur.execute(\"ALTER TABLE orders MODIFY customer_id VARCHAR(50);\")\n",
    "    cur.execute(\"ALTER TABLE reviews MODIFY review_id VARCHAR(50);\")\n",
    "    cur.execute(\"ALTER TABLE reviews MODIFY order_id VARCHAR(50);\")\n",
    "    cur.execute(\"ALTER TABLE sellers MODIFY seller_id VARCHAR(50);\")\n",
    "    cur.execute(\"ALTER TABLE sellers MODIFY sel_zip_code INT;\")\n",
    "    cur.execute(\"ALTER TABLE products MODIFY product_id VARCHAR(50);\")\n",
    "    con.close()\n",
    "    return \"tablas modificadas\"\n",
    "\n",
    "def set_primary_key():\n",
    "    #crear conexion\n",
    "    con = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        passwd=PASSWORD, \n",
    "        db=DATABASE\n",
    "    )\n",
    "    #establecer primarys keys\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"ALTER TABLE customers ADD PRIMARY KEY (customer_id);\")\n",
    "    cur.execute(\"ALTER TABLE customers ADD INDEX (cus_zip_code);\")\n",
    "    cur.execute(\"ALTER TABLE geolocation ADD PRIMARY KEY (geo_zip_code);\")\n",
    "    cur.execute(\"ALTER TABLE geolocation ADD INDEX (geo_zip_code);\")\n",
    "    cur.execute(\"ALTER TABLE order_items ADD COLUMN id_item INT AUTO_INCREMENT PRIMARY KEY;\")\n",
    "    cur.execute(\"ALTER TABLE order_items ADD INDEX (order_id);\")\n",
    "    cur.execute(\"ALTER TABLE order_items ADD INDEX (seller_id);\")\n",
    "    cur.execute(\"ALTER TABLE orders ADD PRIMARY KEY (order_id);\")\n",
    "    cur.execute(\"ALTER TABLE orders ADD INDEX (customer_id);\")\n",
    "    cur.execute(\"ALTER TABLE reviews ADD PRIMARY KEY (review_id);\")\n",
    "    cur.execute(\"ALTER TABLE reviews ADD INDEX (order_id);\")\n",
    "    cur.execute(\"ALTER TABLE sellers ADD PRIMARY KEY (seller_id);\")\n",
    "    cur.execute(\"ALTER TABLE sellers ADD INDEX (sel_zip_code);\")\n",
    "    cur.execute(\"ALTER TABLE products ADD PRIMARY KEY (product_id);\")\n",
    "    \n",
    "    con.close()\n",
    "    return \"Claves primarias creadas\"\n",
    "def set_foreign_key():\n",
    "    #crear conexion\n",
    "    con = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        passwd=PASSWORD,\n",
    "        db=DATABASE\n",
    "    )\n",
    "    #establecer permisos\n",
    "    cur = con.cursor() \n",
    "    cur.execute(\"SET foreign_key_checks=0;\")\n",
    "    #establecer foreign keys\n",
    "    cur.execute(\"ALTER TABLE customers ADD FOREIGN KEY (cus_zip_code) REFERENCES geolocation(geo_zip_code);\")\n",
    "    cur.execute(\"ALTER TABLE order_items ADD FOREIGN KEY (product_id) REFERENCES products(product_id);\")\n",
    "    cur.execute(\"ALTER TABLE order_items ADD FOREIGN KEY (order_id) REFERENCES orders(order_id);\")\n",
    "    cur.execute(\"ALTER TABLE order_items ADD FOREIGN KEY (seller_id) REFERENCES sellers(seller_id);\")\n",
    "    cur.execute(\"ALTER TABLE orders ADD FOREIGN KEY (customer_id) REFERENCES customers(customer_id);\")\n",
    "    cur.execute(\"ALTER TABLE reviews ADD FOREIGN KEY (order_id) REFERENCES orders(order_id);\")\n",
    "    cur.execute(\"ALTER TABLE sellers ADD FOREIGN KEY (sel_zip_code) REFERENCES geolocation(geo_zip_code);\")\n",
    "    con.close()\n",
    "    return \"Claves primarias creadas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating database...\n",
      "extracting data...\n",
      "transforming data...\n"
     ]
    }
   ],
   "source": [
    "# Crear pipeline\n",
    "###################################################\n",
    "print('creating database...')\n",
    "create_db()\n",
    "print('extracting data...')\n",
    "data = extract()\n",
    "print('transforming data...')\n",
    "data = transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "normalizing data...\n",
      "set primary keys...\n",
      "set foreign key\n",
      "\n",
      "TASK COMPLETED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "print('loading data...')\n",
    "load(data)\n",
    "print('normalizing data...')\n",
    "normalize_data()\n",
    "print('set primary keys...')\n",
    "set_primary_key()\n",
    "print('set foreign key')\n",
    "set_foreign_key()\n",
    "print('\\nTASK COMPLETED SUCCESSFULLY!')\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear carga incrmental, se inserta la ruta del archivo para insertar en tabla orders\n",
    "def extract_adic(ruta_archivo):\n",
    "    #se crea la conexion\n",
    "    conexion = create_engine('mysql+mysqlconnector://'+USER+':'+PASSWORD+'@'+HOST+':'+str(PORT)+'/'+DATABASE)\n",
    "    #se lee el archivo\n",
    "    df= pd.read_csv(f\"{ruta_archivo}\")\n",
    "    #se hacen las transformaciones necesarias\n",
    "    df.drop(['order_status'], axis=1, inplace=True)\n",
    "    df['dif_buy_cust'] = (pd.to_datetime(df['order_delivered_customer_date']) - pd.to_datetime(df['order_purchase_timestamp'])).dt.days\n",
    "    df['dif_buy_est'] = (pd.to_datetime(df['order_estimated_delivery_date']) - pd.to_datetime(df['order_purchase_timestamp'])).dt.days\n",
    "    df['dif_cust_est'] = (pd.to_datetime(df['order_estimated_delivery_date']) - pd.to_datetime(df['order_delivered_customer_date'])).dt.days\n",
    "    #se cargan los datos en sql\n",
    "    df.to_sql(name='datos_adicional', index=False, con=conexion)#if_exists='append')\n",
    "    return 'Etl de datos adicionales listo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertar_datos():\n",
    "    #se crea la conexion\n",
    "    con = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        passwd=PASSWORD,\n",
    "        db=DATABASE\n",
    "    )\n",
    "    cur = con.cursor()\n",
    "    #se insertan los datos de la tabla adicional en la tabla orders\n",
    "    cur.execute(\"INSERT INTO orders SELECT * FROM datos_adicional;\")\n",
    "    cur.execute(\"DROP TABLE datos_adicional;\")\n",
    "    con.close()\n",
    "    return \"Datos insertados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extrayendo datos adicionales, cargando a la base\n"
     ]
    }
   ],
   "source": [
    "extract_adic(\"https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/datos_adicional.csv\")#(\"https://raw.githubusercontent.com/lulo76/Proyecto-Final-DTS--05/main/Week%201/datos_adicional.csv\")\n",
    "print(\"extrayendo datos adicionales, cargando a la base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agregando datos a la tabla orders\n"
     ]
    }
   ],
   "source": [
    "insertar_datos()\n",
    "print(\"Agregando datos a la tabla orders\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
